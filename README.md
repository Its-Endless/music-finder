# ğŸµ Local Audio Fingerprinting & Music Recognition

A complete Shazam-style audio recognition system built from scratch using Python.

This project listens to audio, generates spectral fingerprints, stores them in a
database, and identifies songs by matching hashes â€” just like real audio
fingerprinting systems (Shazam, Echoprint, etc.).

It includes:

âœ… Real-time microphone recording  
âœ… Local-peak constellation fingerprinting  
âœ… Hash generation for fast lookup  
âœ… SQLite fingerprint database  
âœ… Matching engine with offset alignment  
âœ… Web API (Flask)  
âœ… Web UI with browser microphone access  
âœ… Batch song ingestion (multi-song fingerprinting)  
âœ… Debug tools (spectrogram + peaks, match diagnostics)

---

# ğŸš€ Features

### ğŸ¤ Record audio & generate fingerprints
Record a snippet and extract spectral peaks (constellation map) using STFT.

### ğŸ§  Fast Hash-based Matching (Shazam-like)
Matches fingerprints using hash collisions + time-offset alignment.

### ğŸ—„ SQLite Database for Fingerprints
Stores:
- song metadata  
- fingerprint hashes  
- time offsets  

### ğŸŒ Flask API
Send any audio file (`wav/mp3/m4a/ogg/webm`) to:
```

POST /match

```
and receive JSON match results.

### ğŸŒ Web UI (HTML + JS)
- Record via browser microphone  
- Auto-send audio to API  
- Display matching results  

---

# ğŸ“¸ Demo Screenshot (optional)
*(Insert your spectrogram or UI screenshot here)*

---

# ğŸ— Project Structure

```

Shazam Clone/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api.py
â”‚   â”œâ”€â”€ capture.py
â”‚   â”œâ”€â”€ fingerprint.py
â”‚   â”œâ”€â”€ matcher.py
â”‚   â”œâ”€â”€ db.py
â”‚   â”œâ”€â”€ debug_peaks.py
â”‚   â”œâ”€â”€ debug_matching.py
â”‚   â””â”€â”€ **init**.py
â”‚
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html           # Web UI
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_basic.py
â”‚
â”œâ”€â”€ fingerprints.db          # (ignored after cleanup)
â”œâ”€â”€ recording.wav            # (ignored)
â”œâ”€â”€ query.wav                # (ignored)
â””â”€â”€ README.md

````

---

# ğŸ”§ Installation

### 1. Clone repository
```bash
git clone https://github.com/<your-username>/Shazam-Clone.git
cd Shazam-Clone
````

### 2. Create & activate environment

```bash
conda create -n shazam python=3.10 -y
conda activate shazam
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

(If you don't have a requirements file, install manually:)

```bash
pip install librosa soundfile pydub sounddevice flask sqlalchemy pytest audioread
```

### 4. Install FFmpeg

Required for `.webm â†’ .wav` conversion.

Download from:
[https://www.gyan.dev/ffmpeg/builds/](https://www.gyan.dev/ffmpeg/builds/)

Add to PATH:

```
C:\ffmpeg\bin
```

Check:

```bash
ffmpeg -version
```

---

# ğŸ™ Record Audio (Testing)

Record 5 seconds:

```bash
python src/capture.py
```

---

# ğŸ§¬ Fingerprint Audio

Store fingerprints in the DB:

```bash
python -m src.fingerprint recording.wav "test_recording"
```

Debug peaks:

```bash
python -m src.debug_peaks recording.wav
```

---

# ğŸ” Match Audio

Match any audio file against the database:

```bash
python -m src.matcher query.wav
```

Expected output:

```
Top 1 candidates:
1. song_id=1 score=713 best_delta=5 name='test_recording' path='recording.wav'
```

---

# ğŸŒ Run the API

```bash
python -m src.api
```

API will run at:

```
http://127.0.0.1:5000
```

### Test with curl:

```bash
curl -X POST -F "file=@recording.wav" http://127.0.0.1:5000/match
```

---

# ğŸ–¥ Web UI

Open:

```
static/index.html
```

Click **ğŸ¤ Record & Identify**
Browser â†’ records audio â†’ sends to API â†’ shows match.

Supports `.webm` audio from browsers using ffmpeg+pydub conversion.

---

# ğŸ“š Add Multiple Songs (Batch Fingerprinting)

Create a folder:

```
songs/
   song1.mp3
   song2.wav
   song3.m4a
   ...
```

Batch script (coming soon):

```bash
python -m src.batch_fingerprint songs/
```

---

# ğŸ§ª Tests

Run tests:

```bash
pytest
```

---

# ğŸ§  How It Works (Brief Architecture)

### 1. STFT Spectrogram

Convert audio â†’ time-frequency domain.

### 2. Peak Picking (Constellation Map)

Find local maxima â†’ frequency-time anchor points.

### 3. Hashing

Pair peaks using:

```
(hash = sha1(freq1, freq2, dt))
```

### 4. Store in DB

Each hash â†’ (song_id, time_offset).

### 5. Matching

Query audio â†’ generate hashes â†’ lookup collisions â†’ align using time-deltas â†’ score.

Very close to the real Shazam patent methodology.

---

# ğŸ“Œ Future Improvements

* Batch song ingestion
* Confidence scoring
* Noise robustness
* Spectrogram UI
* Real-time continuous listening
* Mobile app integration
* Deploy the API to cloud

---

# ğŸ¤ Contributing

PRs welcome!
Open an issue for feature requests or ideas.

---

# ğŸ“„ License

MIT License.

---
